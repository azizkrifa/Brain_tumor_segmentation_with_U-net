{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from  Utils import plot_training_history\n",
    "from Data_processing_utils import data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05f0bc",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "### ðŸ“¦ Architecture Overview\n",
    "\n",
    "The **3D U-Net** follows an encoder-decoder structure with skip connections and is designed to capture both **spatial context** and **fine-grained localization** in volumetric data.\n",
    "\n",
    "#### ðŸ”¹ Encoder Path (Contracting)\n",
    "- Extracts high-level features while reducing spatial resolution.\n",
    "- Each block applies two 3D convolutions followed by batch normalization and ReLU activation.\n",
    "- Downsampling is done using 3D max pooling.\n",
    "\n",
    "#### ðŸ”¹ Bottleneck\n",
    "- The deepest part of the network.\n",
    "- Contains convolutional layers without pooling or upsampling.\n",
    "- Acts as a bridge between encoder and decoder.\n",
    "\n",
    "#### ðŸ”¹ Decoder Path (Expanding)\n",
    "- Gradually restores spatial dimensions using 3D upsampling.\n",
    "- Each upsampling block is followed by concatenation with the corresponding encoder feature map (skip connection), helping retain spatial detail.\n",
    "- Then it applies convolutional layers to refine the merged features.\n",
    "\n",
    "#### ðŸ”¹ Output Layer\n",
    "- A final 3D convolution with softmax activation outputs a probability map for each class, per voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters):\n",
    "    x = layers.Conv3D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    f = conv_block(x, filters)\n",
    "    p = layers.MaxPooling3D((2, 2, 2))(f)\n",
    "    return f, p\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    us = layers.UpSampling3D((2, 2, 2))(x)\n",
    "    concat = layers.Concatenate()([us, skip])\n",
    "    return conv_block(concat, filters)\n",
    "\n",
    "def build_3d_unet(input_shape=(128, 128, 128, 4), num_classes=5):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "    s4, p4 = encoder_block(p3, 256)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = conv_block(p4, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b, s4, 256)\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "    outputs = layers.Conv3D(num_classes, 1, activation='softmax')(d4)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30564160",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### ðŸŽ¯ Dice Coefficient (Multiclass)\n",
    "\n",
    "The **Dice Coefficient** measures the overlap between predicted and ground truth segmentations. Itâ€™s especially useful in medical imaging tasks.\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Per-Class Dice\n",
    "\n",
    "- Converts ground truth and prediction to binary masks for the target class.\n",
    "- Calculates:\n",
    "  \\[\n",
    "  \\text{Dice} = \\frac{2 \\cdot \\text{Intersection} + \\epsilon}{\\text{Sum of areas} + \\epsilon}\n",
    "  \\]\n",
    "- `epsilon` avoids division by zero.\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Multiclass Dice\n",
    "\n",
    "- Averages the Dice score over all classes (4).\n",
    "- Provides a single score reflecting overall segmentation performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient_per_class(y_true, y_pred, class_index, smooth=1e-6):\n",
    "    \n",
    "    # Create binary masks for this class\n",
    "    y_true_c = tf.cast(tf.equal(y_true, class_index), tf.float32)\n",
    "    y_pred_c = tf.cast(tf.equal(tf.argmax(y_pred, axis=-1), class_index), tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_c * y_pred_c)\n",
    "    union = tf.reduce_sum(y_true_c) + tf.reduce_sum(y_pred_c)\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "def multiclass_dice_coefficient(y_true, y_pred, num_classes=5, smooth=1e-6):\n",
    "    dice = 0\n",
    "    for i in range(num_classes):\n",
    "        dice += dice_coefficient_per_class(y_true, y_pred, i, smooth)\n",
    "    return dice / num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a7b2b",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "### ðŸ§ª Model Compilation & Summary\n",
    "\n",
    "After building the 3D U-Net, the model is compiled with the following settings:\n",
    "\n",
    "- **Optimizer**: `Adam` â€” adaptive learning rate optimization.\n",
    "- **Loss Function**: `sparse_categorical_crossentropy` â€” used for multi-class segmentation with integer labels.\n",
    "- **Metric**: `multiclass_dice_coefficient` â€” custom metric to evaluate segmentation overlap across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_3d_unet()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[multiclass_dice_coefficient]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edbbe29",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "### ðŸ“‚ Data Preparation with Generators\n",
    "\n",
    "- Retrieves all subject folder paths from the `train` and `val` directories using `glob`.\n",
    "- Sorts them to ensure consistent ordering.\n",
    "- Initializes data generators for both training and validation sets with a specified `batch_size`\n",
    "- These generators will load and yield data in batches during model training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/content/BraTS2024/Train\"\n",
    "val_dir = \"/content/BraTS2024/Val\"\n",
    "test_dir = \"/content/BraTS2024/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a228cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all subject folders in train and val directories\n",
    "\n",
    "train_subject_dirs = sorted(glob(os.path.join(train_dir, \"*\")))\n",
    "val_subject_dirs = sorted(glob(os.path.join(val_dir, \"*\")))\n",
    "\n",
    "batch_size = 2\n",
    "train_gen = data_generator(train_subject_dirs, batch_size)\n",
    "val_gen = data_generator(val_subject_dirs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ac8f5",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "### ðŸš€ Model Training with Callbacks\n",
    "\n",
    "The model is trained using `model.fit()` with the following configurations:\n",
    "\n",
    "- **Training & Validation Generators**: Yield batches from the subject folders.\n",
    "- **Epochs**: 50 total.\n",
    "- **Steps**: Calculated based on dataset size and batch size.\n",
    "\n",
    "####  Callbacks Used:\n",
    "- **EarlyStopping**: Stops training if `val_loss` doesn't improve for 10 epochs; restores best weights.\n",
    "- **ModelCheckpoint**: Saves the model with the lowest `val_loss` to `/Outputs/best_model.h5`.\n",
    "- **CSVLogger**: Logs training history to `/Outputs/training_log.csv`.\n",
    "- **ReduceLROnPlateau**: Reduces learning rate by half after 3 stagnant validation losses (min LR = 1e-7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd193b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"/Outputs/best_model.h5\", save_best_only=True, monitor='val_loss')\n",
    "\n",
    "csv_logger = CSVLogger('/Outputs/training_log.csv', append=False)\n",
    "\n",
    "training_steps = math.ceil(len(train_subject_dirs) / batch_size)\n",
    "validation_steps = math.ceil(len(val_subject_dirs) / batch_size)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',    # metric to monitor\n",
    "    factor=0.5,            # factor to reduce LR by, new_lr = lr * factor\n",
    "    patience=3,            # number of epochs with no improvement before reducing LR\n",
    "    verbose=1,\n",
    "    min_lr=1e-7            # lower bound on LR\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, checkpoint , csv_logger , reduce_lr]\n",
    ")\n",
    "\n",
    "plot_training_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
