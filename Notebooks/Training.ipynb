{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764b2a4b",
      "metadata": {
        "id": "764b2a4b"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from  Utils import plot_training_history\n",
        "from Data_processing_utils import data_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b05f0bc",
      "metadata": {
        "id": "5b05f0bc"
      },
      "source": [
        "### ‚öôÔ∏è **Architecture Overview**\n",
        "\n",
        "The **Hybrid 3D U-Net** extends the classic encoder‚Äìdecoder design by incorporating **MedNeXt-style residual blocks**, **adaptive normalization**, and **lightweight attention mechanisms**, resulting in a more powerful and efficient segmentation model for volumetric data.\n",
        "\n",
        "\n",
        "#### üîπ Encoder Path (Contracting)\n",
        "- Uses **MedNeXt blocks** instead of standard convolutions.  \n",
        "- Each block includes:\n",
        "  - **Depthwise/Grouped Convolution** for efficient feature extraction.  \n",
        "  - **Pointwise Convolution** for channel mixing.  \n",
        "  - **Adaptive Group Normalization** (auto-selects number of groups, fallback to LayerNorm).  \n",
        "  - **Squeeze-and-Excitation (SE) attention** to recalibrate channel importance.  \n",
        "  - **Residual connections** with optional projection for stable training.  \n",
        "- Downsampling performed with **3D Max Pooling**.\n",
        "\n",
        "\n",
        "#### üîπ Bottleneck\n",
        "- A deep **MedNeXt block** at the lowest resolution.  \n",
        "- Captures global context and high-level features.  \n",
        "\n",
        "\n",
        "#### üîπ Decoder Path (Expanding)\n",
        "- **Upsampling** with 3D transposed convolutions (Conv3DTranspose).  \n",
        "- Skip connections concatenate encoder and decoder features to retain spatial detail.  \n",
        "- Each upsampling stage applies a **MedNeXt block** for refined feature learning.  \n",
        "\n",
        "\n",
        "#### üîπ Output Layer\n",
        "- Final **1√ó1√ó1 convolution** maps decoder features to `num_classes`.  \n",
        "- **Softmax activation** generates voxel-wise class probabilities for segmentation.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42a20fd",
      "metadata": {
        "id": "f42a20fd"
      },
      "outputs": [],
      "source": [
        "# ---------- Adaptive GroupNorm ----------\n",
        "def adaptive_gn(x, filters):\n",
        "    groups = min(8, filters, x.shape[-1])\n",
        "    if x.shape[-1] % groups != 0:\n",
        "        groups = 1  # fallback to LayerNorm\n",
        "    return layers.GroupNormalization(groups=groups)(x)\n",
        "\n",
        "# ---------- MedNeXt-style Block ----------\n",
        "def mednext_block(x, filters, dropout_rate=0.2):\n",
        "    input_channels = x.shape[-1]\n",
        "\n",
        "    # Depthwise / grouped conv\n",
        "    groups = min(8, filters, input_channels)\n",
        "    if input_channels % groups != 0:\n",
        "        groups = 1\n",
        "    x_dw = layers.Conv3D(filters, 3, padding=\"same\", groups=groups, use_bias=False)(x)\n",
        "    x_dw = adaptive_gn(x_dw, filters)\n",
        "    x_dw = layers.ReLU()(x_dw)\n",
        "\n",
        "    # Pointwise conv\n",
        "    x_pw = layers.Conv3D(filters, 1, padding=\"same\", use_bias=False)(x_dw)\n",
        "    x_pw = adaptive_gn(x_pw, filters)\n",
        "\n",
        "    # Lightweight attention (Squeeze-and-Excitation)\n",
        "    se = layers.GlobalAveragePooling3D()(x_pw)\n",
        "    se = layers.Dense(max(filters // 4, 1), activation=\"relu\")(se)\n",
        "    se = layers.Dense(filters, activation=\"sigmoid\")(se)\n",
        "    se = layers.Reshape((1, 1, 1, filters))(se)\n",
        "    x_att = layers.Multiply()([x_pw, se])\n",
        "\n",
        "    # Dropout\n",
        "    x_att = layers.Dropout(dropout_rate)(x_att)\n",
        "\n",
        "    # Residual connection\n",
        "    if input_channels == filters:\n",
        "        x_out = layers.Add()([x, x_att])\n",
        "    else:\n",
        "        x_res = layers.Conv3D(filters, 1, padding=\"same\")(x)\n",
        "        x_out = layers.Add()([x_res, x_att])\n",
        "\n",
        "    return layers.ReLU()(x_out)\n",
        "\n",
        "# ---------- Encoder & Decoder ----------\n",
        "def encoder_block(x, filters):\n",
        "    f = mednext_block(x, filters)\n",
        "    p = layers.MaxPooling3D((2,2,2))(f)\n",
        "    return f, p\n",
        "\n",
        "def decoder_block(x, skip, filters):\n",
        "    us = layers.Conv3DTranspose(filters, 2, strides=2, padding=\"same\")(x)\n",
        "    concat = layers.Concatenate()([us, skip])\n",
        "    return mednext_block(concat, filters)\n",
        "\n",
        "# ---------- Full Hybrid UNet ----------\n",
        "def build_hybrid_unet(input_shape=(128,128,128,4), num_classes=5):\n",
        "    inputs = tf.keras.Input(shape=input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Encoder\n",
        "    s1, p1 = encoder_block(inputs, 32)\n",
        "    s2, p2 = encoder_block(p1, 64)\n",
        "    s3, p3 = encoder_block(p2, 128)\n",
        "    s4, p4 = encoder_block(p3, 256)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = mednext_block(p4, 512)\n",
        "\n",
        "    # Decoder\n",
        "    d1 = decoder_block(b, s4, 256)\n",
        "    d2 = decoder_block(d1, s3, 128)\n",
        "    d3 = decoder_block(d2, s2, 64)\n",
        "    d4 = decoder_block(d3, s1, 32)\n",
        "\n",
        "    outputs = layers.Conv3D(num_classes, 1, activation=\"softmax\")(d4)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30564160",
      "metadata": {
        "id": "30564160"
      },
      "source": [
        "### üéØ Dice Coefficient & Loss (Multiclass)\n",
        "\n",
        "The **Dice Coefficient** measures the overlap between predicted and ground truth segmentations. It‚Äôs particularly useful in medical imaging tasks where class imbalance is common.\n",
        "\n",
        "\n",
        "\n",
        "#### üîπ Per-Class Dice Coefficient\n",
        "- Extracts binary masks for a **specific class**:\n",
        "  - `y_true_c`: ground truth mask for the target class.  \n",
        "  - `y_pred_c`: predicted mask obtained from `argmax` of the logits.  \n",
        "- Uses `epsilon` (`smooth`) to avoid division by zero.\n",
        "\n",
        "\n",
        "\n",
        "#### üîπ Multiclass Dice Coefficient\n",
        "- Iterates over all `num_classes` (default = 5).  \n",
        "- Averages the per-class Dice scores.  \n",
        "- Produces a **single global metric** reflecting segmentation performance across all classes.  \n",
        "\n",
        "\n",
        "\n",
        "#### üîπ Dice Loss\n",
        "- Converts ground truth to **one-hot encoding**.  \n",
        "- Flattens predictions and labels to compute per-class overlap.  \n",
        "- Returns the complement of the mean Dice score across classes.  \n",
        "\n",
        "\n",
        "\n",
        "#### üîπ Hybrid Loss\n",
        "- Combines **Sparse Categorical Cross-Entropy (CE)** with **Dice Loss**.  \n",
        "- Balances **class-wise prediction accuracy** with **segmentation overlap quality**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b6dde5",
      "metadata": {
        "id": "68b6dde5"
      },
      "outputs": [],
      "source": [
        "def dice_coefficient_per_class(y_true, y_pred, class_index, smooth=1e-6):\n",
        "    # Ground truth mask for this class\n",
        "    y_true_c = tf.cast(tf.equal(y_true, class_index), tf.float32)\n",
        "    # Prediction mask for this class\n",
        "    y_pred_c = tf.cast(tf.equal(tf.argmax(y_pred, axis=-1), class_index), tf.float32)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_c * y_pred_c)\n",
        "    union = tf.reduce_sum(y_true_c) + tf.reduce_sum(y_pred_c)\n",
        "\n",
        "    return (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "def multiclass_dice_coefficient(y_true, y_pred, num_classes=5, smooth=1e-6):\n",
        "    dice = 0\n",
        "    for i in range(num_classes):\n",
        "        dice += dice_coefficient_per_class(y_true, y_pred, i, smooth)\n",
        "    return dice / num_classes\n",
        "\n",
        "\n",
        "# ---------- Dice Loss ----------\n",
        "\n",
        "def dice_loss(y_true, y_pred, num_classes=5, smooth=1e-6):\n",
        "    # One-hot encode ground truth\n",
        "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)\n",
        "\n",
        "    # Flatten (batch, H, W, D, C) ‚Üí (batch, -1, C)\n",
        "    y_true = tf.reshape(y_true, [-1, num_classes])\n",
        "    y_pred = tf.reshape(y_pred, [-1, num_classes])\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=0)\n",
        "    union = tf.reduce_sum(y_true + y_pred, axis=0)\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return 1 - tf.reduce_mean(dice)\n",
        "\n",
        "def hybrid_loss(y_true, y_pred):\n",
        "    ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    return 0.5 * ce + 0.5 * dice_loss(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "872a7b2b",
      "metadata": {
        "id": "872a7b2b"
      },
      "source": [
        "\n",
        "----\n",
        "\n",
        "### üß™ Model Compilation & Summary\n",
        "\n",
        "After building the 3D U-Net, the model is compiled with the following settings:\n",
        "\n",
        "- **Optimizers**:  \n",
        "  - `Adam` (learning rate = 1e-4) ‚Äî adaptive learning rate optimization.  \n",
        "  - `SGD` (learning rate = 1e-4, momentum = 0.9) ‚Äî stochastic gradient descent with momentum.  \n",
        "\n",
        "- **Loss Function**: `hybrid_loss` ‚Äî combines Sparse Categorical Cross-Entropy and Dice Loss for balanced optimization.  \n",
        "\n",
        "- **Metric**: `multiclass_dice_coefficient` ‚Äî custom metric to evaluate segmentation overlap across all classes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accb6012",
      "metadata": {
        "id": "accb6012"
      },
      "outputs": [],
      "source": [
        "model = build_3d_unet()\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "# With Adam\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss = hybrid_loss,   # Soft Dice + CE\n",
        "    metrics=[multiclass_dice_coefficient])\n",
        "\n",
        "# Then with SGD\n",
        "model.compile(\n",
        "     optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n",
        "     loss = hybrid_loss,\n",
        "     metrics=[multiclass_dice_coefficient])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edbbe29",
      "metadata": {
        "id": "9edbbe29"
      },
      "source": [
        "\n",
        "-----\n",
        "\n",
        "### üìÇ Data Preparation with Generators\n",
        "\n",
        "- Retrieves all subject folder paths from the `train` and `val` directories using `glob`.\n",
        "- Sorts them to ensure consistent ordering.\n",
        "- Initializes data generators for both training and validation sets with a specified `batch_size`\n",
        "- These generators will load and yield data in batches during model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8563fc21",
      "metadata": {
        "id": "8563fc21"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/BraTS2024/train\"\n",
        "val_dir = \"/content/BraTS2024/val\"\n",
        "test_dir = \"/content/BraTS2024/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a228cab",
      "metadata": {
        "id": "4a228cab"
      },
      "outputs": [],
      "source": [
        "# Get list of all subject folders in train and val directories\n",
        "\n",
        "train_subject_dirs = sorted(glob(os.path.join(train_dir, \"*\")))\n",
        "val_subject_dirs = sorted(glob(os.path.join(val_dir, \"*\")))\n",
        "\n",
        "batch_size = 2\n",
        "train_gen = data_generator(train_subject_dirs, batch_size)\n",
        "val_gen = data_generator(val_subject_dirs, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4ac8f5",
      "metadata": {
        "id": "4b4ac8f5"
      },
      "source": [
        "\n",
        "-----\n",
        "\n",
        "### üöÄ Model Training with Callbacks\n",
        "\n",
        "The model is trained using `model.fit()` with the following configurations:\n",
        "\n",
        "- **Training & Validation Generators**: Yield batches from the subject folders.\n",
        "- **Epochs**: 50 total.\n",
        "- **Steps**: Calculated based on dataset size and batch size.\n",
        "\n",
        "####  Callbacks Used:\n",
        "- **EarlyStopping**: Stops training if `val_loss` doesn't improve for 10 epochs; restores best weights.\n",
        "- **ModelCheckpoint**: Saves the model with the lowest `val_loss` to `/Outputs/best_model.h5`.\n",
        "- **CSVLogger**: Logs training history to `/Outputs/training_log.csv`.\n",
        "- **ReduceLROnPlateau**: Reduces learning rate by half after 3 stagnant validation losses (min LR = 1e-7)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd193b5d",
      "metadata": {
        "id": "bd193b5d"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_multiclass_dice_coefficient', patience=10, mode='max' , restore_best_weights=True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/Outputs/best_model.h5\", save_best_only=True, mode='max', monitor='val_multiclass_dice_coefficient')\n",
        "\n",
        "csv_logger = CSVLogger('/Outputs/training_log.csv', append=True)\n",
        "\n",
        "training_steps = math.ceil(len(train_subject_dirs) / batch_size)\n",
        "validation_steps = math.ceil(len(val_subject_dirs) / batch_size)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_multiclass_dice_coefficient',    # metric to monitor\n",
        "    factor=0.5,            # factor to reduce LR by, new_lr = lr * factor\n",
        "    patience=3,            # number of epochs with no improvement before reducing LR\n",
        "    verbose=1,\n",
        "    min_lr=1e-7            # lower bound on LR\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=training_steps,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, checkpoint , csv_logger , reduce_lr]\n",
        ")\n",
        "\n",
        "plot_training_history()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}